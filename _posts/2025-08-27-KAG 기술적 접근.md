---
layout: post
title: KAG 자세히 살펴보기
subtitle: KAG의 WHY와 HOW의 기술적 접근
author: Garpas
categories: LLM
tags:
  - LLM
  - why-how
  - "#KAG"
excerpt_image: /assets/images/thumbnails/mayling_l.png
---
이 포스트에서는 **KAG(Knowledge AUGMENTED GENERATION)** 에대하여 기술적으로 접근합니다.

# 0. Prior Knowledge
- LLM
- RAG
- Graph 구조
# 1. Background & WHY
RAG의 단점
1. including the gap between vector similarity
2. gap between the relevance of knowledge reasoning

enhance the performance of the RAG system in multi-hop and cross-paragraph tasks, knowledge graph, renowned for strong reasoning capabilities, have been introduced into the RAG technical framework
# 2. HOW
### KG(Knowledge Graph) LLMFriSPG
Neo4j

Builder: designed for building offline indexes "LLMFriSPG"
Solver: a Logical-form-guided hybrid reasoning solver that integrates LLM reasoning, knowledge reasoning
Model: optimizes the capabilities needed by each module based on a general language model

LLM을 이용하여 entities, events, concepts relations를 데이터셋에서 추출
청크마다 Entity를 먼저 추출 -> event set와 Relation set을 추출
we use LLMs to generate built-in properties description, summary, semanticType, spgClass, descripitonOfSemanticType by default for each instance e at one time
# 3. Use Cases
# 4. Source
